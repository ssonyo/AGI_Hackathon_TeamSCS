
from pathlib import Path
import os
import pandas as pd
import re
from typing import Type
import streamlit as st
from dotenv import load_dotenv
from langchain_community.document_loaders import UnstructuredFileLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.embeddings import CacheBackedEmbeddings
from langchain.schema.runnable import RunnableLambda, RunnablePassthrough
from langchain.storage import LocalFileStore
from langchain_upstage import ChatUpstage, UpstageEmbeddings, UpstageDocumentParseLoader
from langchain.prompts import PromptTemplate
from langchain.agents import initialize_agent, Tool, AgentExecutor
from langchain.agents.agent_types import AgentType
from langchain.agents.openai_functions_agent.agent_token_buffer_memory import AgentTokenBufferMemory
from langchain.agents.format_scratchpad.openai_tools import format_to_openai_tool_messages
from langchain.callbacks.base import BaseCallbackHandler
from pydantic import BaseModel, Field
import requests
from langchain_community.tools import BaseTool


load_dotenv()
upstage_api_key = os.environ.get("UPSTAGE_API_KEY")

llm = ChatUpstage(
    api_key=os.getenv("UPSTAGE_API_KEY"),
    model="solar-pro",
    temperature=0.2,
    streaming=True,
)



@st.cache_resource(show_spinner="ğŸ“„ ë¬¸ì„œë¥¼ ì„ë² ë”© ì¤‘ì…ë‹ˆë‹¤...")
def embed_file(file):
    file_path = f"./.cache/files/{file.name}"
    with open(file_path, "wb") as f:
        f.write(file.read())

    docs = UpstageDocumentParseLoader(file_path, split="page").load()
    splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=600, chunk_overlap=100)
    chunks = splitter.split_documents(docs)

    embeddings = UpstageEmbeddings(
        api_key=os.getenv("UPSTAGE_API_KEY"),
        model="solar-embedding-1-large"
    )
    cache_dir = LocalFileStore(f"./.cache/embeddings/{file.name}")
    cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)

    vectorstore = FAISS.from_documents(chunks, cached_embeddings)
    return vectorstore.as_retriever()



class KoreanStockSymbolSearchToolArgsSchema(BaseModel):
    query: str = Field(
        description="ê²€ìƒ‰í•˜ê³ ì í•˜ëŠ” í•œêµ­ ê¸°ì—…ëª…. ì˜ˆ: ì‚¼ì„±ì „ì, ë„¤ì´ë²„"
    )

class KoreanStockSymbolSearchTool(BaseTool):
    name: str = "KoreanStockSymbolSearchTool"
    description: str = """
    í•œêµ­ ê¸°ì—…ì˜ ì£¼ì‹ ì¢…ëª© ì½”ë“œë¥¼ ì°¾ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
    ê¸°ì—…ëª…ì„ ì…ë ¥í•˜ë©´ í•´ë‹¹ ê¸°ì—…ì˜ ì¢…ëª© ì½”ë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    args_schema: Type[KoreanStockSymbolSearchToolArgsSchema] = KoreanStockSymbolSearchToolArgsSchema

    def _run(self, query):
        headers = {"Authorization": f"Bearer {upstage_api_key}"}
        response = requests.get(
            f"{UPSTAGE_BASE_URL}/search?keyword={query}",
            headers=headers
        )
        return response.json()

class KoreanCompanyOverviewArgsSchema(BaseModel):
    symbol: str = Field(
        description="ê¸°ì—…ì˜ ì¢…ëª© ì½”ë“œ. ì˜ˆ: 005930 (ì‚¼ì„±ì „ì)",
    )

class KoreanCompanyOverviewTool(BaseTool):
    name: str = "KoreanCompanyOverview"
    description: str = """
    í•œêµ­ ê¸°ì—…ì˜ ê¸°ë³¸ ì •ë³´ë¥¼ ì¡°íšŒí•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
    ì¢…ëª© ì½”ë“œë¥¼ ì…ë ¥í•˜ë©´ ê¸°ì—…ì˜ ê°œìš” ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    args_schema: Type[KoreanCompanyOverviewArgsSchema] = KoreanCompanyOverviewArgsSchema

    def _run(self, symbol):
        headers = {"Authorization": f"Bearer {upstage_api_key}"}
        response = requests.get(
            f"{UPSTAGE_BASE_URL}/company/{symbol}/overview",
            headers=headers
        )
        return response.json()

agent = initialize_agent(
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,  # âœ… ì´ê±¸ë¡œ ë°”ê¾¸ê¸°
    verbose=True,
    handle_parsing_errors=True,
    tools=[
        KoreanStockSymbolSearchTool(),
        KoreanCompanyOverviewTool(),
        # í•„ìš”í•œ ë‹¤ë¥¸ ë„êµ¬ë“¤ë„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
    ],
)

prompt = "ë„¤ì´ë²„ì˜ ì£¼ì‹ ì •ë³´ë¥¼ ë¶„ì„í•´ì„œ íˆ¬ì ê°€ì¹˜ê°€ ìˆëŠ”ì§€ ì•Œë ¤ì¤˜"

agent.invoke(prompt) 